<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="overview">Overview</h2> <p>This project is my implementation for the <strong>“SenNet + HOA – Hacking the Human Vasculature in 3D”</strong> Kaggle competition. The task is to segment blood vessels in large <strong>3D TIFF scans of human kidneys</strong> (&gt;40 GB of data). :contentReference[oaicite:8]{index=8}</p> <p>Because competition rules prohibit releasing the dataset, only the code and modeling pipeline are public, but they are fully reproducible if you have access to the original data.</p> <h2 id="method">Method</h2> <ul> <li>I use a <strong>U-Net architecture</strong> for volumetric segmentation of the 3D scans. :contentReference[oaicite:9]{index=9}</li> <li>The model predicts voxel-wise vessel masks, which are then converted into <strong>run-length encoded (RLE) masks</strong> to match the Kaggle submission format. :contentReference[oaicite:10]{index=10}</li> <li>The repository includes: <ul> <li>Notebooks for training and validation (<code class="language-plaintext highlighter-rouge">U_net.ipynb</code>).</li> <li>Utilities for handling large TIFF volumes efficiently.</li> <li>Code that transforms U-Net outputs into RLE strings for submission.</li> </ul> </li> </ul> <h2 id="highlights">Highlights</h2> <ul> <li>Hands-on experience with <strong>3D medical image segmentation</strong> on large datasets.</li> <li>Practical handling of <strong>GPU memory</strong> and I/O constraints for 40GB+ of volumetric data.</li> <li>A reusable template for future <strong>Kaggle medical imaging</strong> or 3D segmentation challenges.</li> </ul> </body></html>