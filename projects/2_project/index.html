<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>cDDPM is a PyTorch implementation of <strong>classifier-free diffusion guidance</strong>, with experiments on how U-Net depth, width, and attention affect the trade-off between sample quality and diversity.</p> <hr> <h2 id="-summary">üîç Summary</h2> <p>Instead of using a separate classifier at sampling time, classifier-free guidance trains a single diffusion backbone in two modes‚Äî<strong>conditional</strong> and <strong>unconditional</strong>‚Äîand combines their scores with a tunable guidance scale. This project:</p> <ul> <li>Implements a DDPM-style backbone with classifier-free guidance.</li> <li>Exposes the guidance weight as a simple knob for quality vs. diversity.</li> <li>Uses the implementation as a sandbox to study architectural tweaks.</li> </ul> <hr> <h2 id="-architecture--experiments">üß† Architecture &amp; experiments</h2> <ul> <li>U-Net backbone with configurable: <ul> <li>Number of channels per stage.</li> <li>Attention blocks at chosen resolutions.</li> </ul> </li> <li>Experiments on: <ul> <li>Varying guidance scales and observing mode collapse vs. sharpness.</li> <li>Changing attention configuration (heads, resolutions) and U-Net depth.</li> </ul> </li> </ul> <hr> <h2 id="-github-repository">üìÇ GitHub repository</h2> <ul> <li>Code &amp; training scripts: <strong><a href="https://github.com/manhbeo/cDDPM" rel="external nofollow noopener" target="_blank">github.com/manhbeo/cDDPM</a></strong> </li> <li>Reference: <em>Classifier-Free Diffusion Guidance</em> (Ho &amp; Salimans, 2022, arXiv:2207.12598).</li> </ul> </body></html>