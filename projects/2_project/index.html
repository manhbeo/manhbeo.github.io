<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="overview">Overview</h2> <p>This project implements <strong>classifier-free diffusion guidance</strong> (Ho &amp; Salimans, 2022) in PyTorch. :contentReference[oaicite:2]{index=2}<br> Instead of using a separate classifier to guide sampling, classifier-free guidance jointly trains <strong>conditional</strong> and <strong>unconditional</strong> diffusion models and mixes their score estimates at sampling time, trading off sample quality vs. diversity through a single guidance weight.</p> <p>Starting from a faithful implementation of the original method, I then explore architectural and training-time modifications to better understand how guidance interacts with the <strong>U-Net backbone</strong> and <strong>self-attention</strong> layers.</p> <h2 id="what-i-implemented">What I implemented</h2> <ul> <li>A minimal yet complete <strong>DDPM-style diffusion model</strong> (<code class="language-plaintext highlighter-rouge">diffusion.py</code>, <code class="language-plaintext highlighter-rouge">model.py</code>) with classifier-free guidance.</li> <li>Training loop that jointly learns conditional and unconditional score networks, matching the setup in the original paper. :contentReference[oaicite:3]{index=3}</li> <li>Sampling code that exposes a <strong>guidance scale</strong> hyperparameter to control quality vs. diversity.</li> <li>Checkpointing and utilities for experimenting with different guidance strengths (weights).</li> </ul> <h2 id="architecture--experiments">Architecture &amp; experiments</h2> <ul> <li> <strong>U-Net backbone</strong> with attention blocks, where I: <ul> <li>Modify the <strong>attention mechanism</strong> (number of heads, attention resolutions).</li> <li>Vary U-Net depth/width and compare their effect under strong vs. weak guidance.</li> </ul> </li> <li>Ablation studies on: <ul> <li>Guidance scales (how far we can push quality before diversity collapses).</li> <li>Different conditioning setups (e.g., class labels, simple text/labels).</li> </ul> </li> </ul> <p>Overall, cDDPM serves as a compact codebase for experimenting with <strong>guidance strategies and architectural tweaks</strong> in diffusion models.</p> </body></html>